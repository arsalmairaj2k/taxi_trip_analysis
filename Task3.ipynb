{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4836161e-bda2-40ce-b9da-454ab21662a1",
   "metadata": {},
   "source": [
    "# Open notebook in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ec9316-e9aa-4e75-891a-e70b13ded336",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arsalmairaj2k/taxi_trip_analysis/blob/main/Task3.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2d2a7a-6a8e-4083-b36d-b83a5ef5455c",
   "metadata": {},
   "source": [
    "# Task 3: Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960a894-42f1-48e6-a57d-80d934b44552",
   "metadata": {},
   "source": [
    "# Load Dataset\r\n",
    "Just like the previous task, we load our dataset from our GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "001537a8-8ee2-4a29-b358-ca0b687f0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "GITHUB_URL = \"https://github.com/arsalmairaj2k/taxi_trip_analysis/raw/main/TaxiTripData.xlsx\"\n",
    "df = pd.read_excel(GITHUB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b34abb-48a7-43c4-850e-ff70a7fa20d6",
   "metadata": {},
   "source": [
    "# 1. Handle missing values(drop, fill with median/mean/mode, or use imputation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d83d39-f827-46ee-8774-c591b9154303",
   "metadata": {},
   "source": [
    "## Identify Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f5277018-cf62-4902-8734-2b6bcd3716f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values per Column:\n",
      "VendorID              2131\n",
      "passenger_count       2131\n",
      "RatecodeID            2131\n",
      "store_and_fwd_flag    2131\n",
      "payment_type          2131\n",
      "dtype: int64\n",
      "\n",
      "Total Missing Values in Dataset: 10655\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "\n",
    "# Display columns with missing values\n",
    "print(\"Missing Values per Column:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Total missing values in the dataset\n",
    "total_missing = df.isnull().sum().sum()\n",
    "print(f\"\\nTotal Missing Values in Dataset: {total_missing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a6e227-2cc1-4e9f-bc89-820570097561",
   "metadata": {},
   "source": [
    "As done in the previous task and also explained, some machine learning algorithms can't perfrom efficiently without complete data so we do what we did in previous task by using imputation provided by sklearn, but this time we replace missing numerical values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "615d927c-dcfb-4d34-9128-5cb84c0764ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0       1.0  2020-01-01 00:28:00   2020-01-01 00:33:00              1.0   \n",
      "1       1.0  2020-01-01 00:35:00   2020-01-01 00:43:00              1.0   \n",
      "2       1.0  2020-01-01 00:47:00   2020-01-01 00:53:00              1.0   \n",
      "3       1.0  2020-01-01 00:55:00   2020-01-01 01:00:00              1.0   \n",
      "4       2.0  2020-01-01 00:01:00   2020-01-01 00:04:00              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
      "0            1.2         1.0                  N         238.0         239.0   \n",
      "1            1.2         1.0                  N         239.0         238.0   \n",
      "2            0.6         1.0                  N         238.0         238.0   \n",
      "3            0.8         1.0                  N         238.0         151.0   \n",
      "4            0.0         1.0                  N         193.0         193.0   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0           1.0          6.0    3.0      0.5        1.47           0.0   \n",
      "1           1.0          7.0    3.0      0.5        1.50           0.0   \n",
      "2           1.0          6.0    3.0      0.5        1.00           0.0   \n",
      "3           1.0          5.5    0.5      0.5        1.36           0.0   \n",
      "4           2.0          3.5    0.5      0.5        0.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  \n",
      "0                    0.3         11.27                   2.5  \n",
      "1                    0.3         12.30                   2.5  \n",
      "2                    0.3         10.80                   2.5  \n",
      "3                    0.3          8.16                   0.0  \n",
      "4                    0.3          4.80                   0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Selecting only numeric features (excluding timestamps and categorical variables)\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Using Median Imputation on numeric columns only\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df[numeric_cols] = imputer.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Handling missing values in categorical columns with mode (as done before as well)\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df.loc[:, col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8d99c-6471-4152-a14a-34db18fa67aa",
   "metadata": {},
   "source": [
    "# 2. Convert categorical features to numerical (One-Hot Encoding or Label Encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eaa2a498-4b41-4e08-a779-25741ed313b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0       1.0  2020-01-01 00:28:00   2020-01-01 00:33:00              1.0   \n",
      "1       1.0  2020-01-01 00:35:00   2020-01-01 00:43:00              1.0   \n",
      "2       1.0  2020-01-01 00:47:00   2020-01-01 00:53:00              1.0   \n",
      "3       1.0  2020-01-01 00:55:00   2020-01-01 01:00:00              1.0   \n",
      "4       2.0  2020-01-01 00:01:00   2020-01-01 00:04:00              1.0   \n",
      "\n",
      "   trip_distance  RatecodeID  PULocationID  DOLocationID  payment_type  \\\n",
      "0            1.2         1.0         238.0         239.0           1.0   \n",
      "1            1.2         1.0         239.0         238.0           1.0   \n",
      "2            0.6         1.0         238.0         238.0           1.0   \n",
      "3            0.8         1.0         238.0         151.0           1.0   \n",
      "4            0.0         1.0         193.0         193.0           2.0   \n",
      "\n",
      "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0          6.0    3.0      0.5        1.47           0.0   \n",
      "1          7.0    3.0      0.5        1.50           0.0   \n",
      "2          6.0    3.0      0.5        1.00           0.0   \n",
      "3          5.5    0.5      0.5        1.36           0.0   \n",
      "4          3.5    0.5      0.5        0.00           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  \\\n",
      "0                    0.3         11.27                   2.5   \n",
      "1                    0.3         12.30                   2.5   \n",
      "2                    0.3         10.80                   2.5   \n",
      "3                    0.3          8.16                   0.0   \n",
      "4                    0.3          4.80                   0.0   \n",
      "\n",
      "   store_and_fwd_flag_Y  \n",
      "0                     0  \n",
      "1                     0  \n",
      "2                     0  \n",
      "3                     0  \n",
      "4                     0  \n"
     ]
    }
   ],
   "source": [
    "# Ensure 'store_and_fwd_flag' is treated as a string before encoding\n",
    "df['store_and_fwd_flag'] = df['store_and_fwd_flag'].astype(str)\n",
    "\n",
    "# Apply One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['store_and_fwd_flag'], drop_first=True)\n",
    "\n",
    "# Convert the new column to integer type (0 and 1)\n",
    "df['store_and_fwd_flag_Y'] = df['store_and_fwd_flag_Y'].astype(int)\n",
    "\n",
    "# Display the first few rows to verify the transformation\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226b1a5-6d8b-4712-b2ed-7f140d2fc38c",
   "metadata": {},
   "source": [
    "# 3. Scale numerical features using  MinMax Scalin\n",
    "Why MinMax Scaling?\n",
    "\n",
    "It scales all numerical features to a range of 0 and 1, making the data suitable for ML models.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1092756-e181-4f53-9a31-540c5ce6935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0       0.0  2020-01-01 00:28:00   2020-01-01 00:33:00         0.111111   \n",
      "1       0.0  2020-01-01 00:35:00   2020-01-01 00:43:00         0.111111   \n",
      "2       0.0  2020-01-01 00:47:00   2020-01-01 00:53:00         0.111111   \n",
      "3       0.0  2020-01-01 00:55:00   2020-01-01 01:00:00         0.111111   \n",
      "4       1.0  2020-01-01 00:01:00   2020-01-01 00:04:00         0.111111   \n",
      "\n",
      "   trip_distance  RatecodeID  PULocationID  DOLocationID  payment_type  \\\n",
      "0       0.083085         0.0      0.897727      0.901515      0.000000   \n",
      "1       0.083085         0.0      0.901515      0.897727      0.000000   \n",
      "2       0.080952         0.0      0.897727      0.897727      0.000000   \n",
      "3       0.081663         0.0      0.897727      0.568182      0.000000   \n",
      "4       0.078820         0.0      0.727273      0.727273      0.333333   \n",
      "\n",
      "   fare_amount     extra   mta_tax  tip_amount  tolls_amount  \\\n",
      "0     0.502423  0.714286  0.263158    0.018534      0.031898   \n",
      "1     0.502827  0.714286  0.263158    0.018600      0.031898   \n",
      "2     0.502423  0.714286  0.263158    0.017505      0.031898   \n",
      "3     0.502221  0.535714  0.263158    0.018293      0.031898   \n",
      "4     0.501414  0.535714  0.263158    0.015317      0.031898   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  \\\n",
      "0                    1.0      0.504536              0.952381   \n",
      "1                    1.0      0.504950              0.952381   \n",
      "2                    1.0      0.504347              0.952381   \n",
      "3                    1.0      0.503284              0.476190   \n",
      "4                    1.0      0.501932              0.476190   \n",
      "\n",
      "   store_and_fwd_flag_Y  \n",
      "0                   0.0  \n",
      "1                   0.0  \n",
      "2                   0.0  \n",
      "3                   0.0  \n",
      "4                   0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Selecting only numeric columns (excluding the target variable 'fare_amount' if needed)\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Initialize MinMaxScaler (scales values between 0 and 1)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply scaling\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "# Display first few rows to verify\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97702613-9a58-4e43-a1eb-8a09e16530d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
